# AI仮想キーボードシステム (AI 가상 키보드 시스템)

概要 (개요)
本プロジェクトは、ウェブカメラとAI技術を活用し、物理的なキーボードなしでテキスト入力を可能にする「AI仮想キーボードシステム」を開発することを目的とします。 既存の物理キーボードが持つ携帯性の低さや、従来の仮想キーボードが抱える疲労感や高い誤打率といった課題を解決します。 紙に印刷したキーボードをウェブカメラで認識させ、その上の指の動きをAIが解析することで、物理キーボードの正確性と仮想キーボードの空間的な自由度を両立させる、新しい入力体験を提供します。

技術スタック (기술 스택)
言語: Python

フレームワーク: PyTorch

ライブラリ:

キーボード認識: YOLOv5

手のランドマーク検出: MediaPipe

実行方法 (실행 방법)

すべてのファイルをダウンロードします。 (모든 파일을 다운로드합니다.)
リポジトリ内の学習済みモデルファイル(.pt)を含む、すべてのファイルをダウンロードしてください。

スクリプトを実行します。 (스크립트를 실행합니다.)

python AIkeytyp.py
動作原理 (동작 원리)
1. キーボード認識 (YOLOv5)
YOLOv5モデルを利用して、ウェブカメラの映像からキーボードの各キーをリアルタイムで検出します。

課題: 紙のキーボードは使用中に動いたり変形したりするため、キーの座標がずれてしまうという問題がありました。

解決策: この問題を解決するため、「アフィン変換」アルゴリズムを導入しました。 3つの基準キーの座標変化を追跡するだけで、座標系全体の幾何学的な変換をリアルタイムに計算し、キーボード全体の動きを最小限の演算で正確に補正します。

2. 手の動き認識 (TCN)
MediaPipeを通じて取得した手の3Dランドマーク座標を、時系列データとして処理するTCN (Temporal Convolutional Network) モデルで学習させ、「タイピング」動作を認識します。

データ品質の確保: 画面基準の座標(landmarks)ではなく、手の中心を基準とする3D座標(world_landmarks)を使用することで、手の動きによる深度(Z軸)のブレを最小限に抑え、安定したデータ品質を確保しました。

モデル選択: 従来のRNN系列モデル(LSTMなど)よりも並列演算が可能で学習速度が速く、Dilated Convolutionによって少ない計算量で全体的な文脈を把握できるTCNを採用しました。

最大の課題と解決策：データ不均衡問題 (가장 큰 과제와 해결책: 데이터 불균형 문제)
開発過程で直面した最大の課題は、学習データの約80%が「入力なし」の状態であるという、極端なデータ不均衡でした。 このままでは、モデルが本当に検出したい「タイピング」の瞬間を見逃してしまうため、以下の2つの戦略で解決しました。

1. T-SMOTEによるデータ生成
時系列データに特化したオーバーサンプリング手法であるT-SMOTEを導入しました。 まず不均衡データで基準モデルを学習させ、「タイピングか否か最も曖昧な」データを特定します。 T-SMOTEは、その曖昧なデータに基づいて新しい「タイピング」データをインテリジェントに合成し、データセットのバランスを整えることで、モデルの弁別力を最大化しました。

2. オンラインデータ拡張
限られたデータを最大限に活用するため、訓練の都度リアルタイムでデータを変形させるオンラインデータ拡張を適用しました。 左右反転、回転、スケール、ノイズ追加といった処理により、多様な実使用環境への般化性能を高め、モデルの過学習を効果的に防止しました。
